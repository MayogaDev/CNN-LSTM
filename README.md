# üñêÔ∏è **Real-Time Peruvian Sign Language Recognition using MediaPipe**

### üìÖ **Duration**: April 2024 - Present  
### üè´ **Associated with**: Universidad Nacional de San Agust√≠n de Arequipa  

---

## üìù **Project Overview**  
This project introduces a cutting-edge system for **real-time recognition of Peruvian Sign Language (LSP)**, utilizing advanced technologies such as **MediaPipe** for feature extraction and **Long Short-Term Memory (LSTM)** networks for sequential data analysis. The system addresses the communication barrier faced by the deaf community in Peru, aiming to promote **social inclusion, educational accessibility**, and equitable opportunities.

By combining computer vision with deep learning, this initiative takes a step toward redefining assistive technologies, enabling effortless interaction between hearing and non-hearing individuals.

---

## üöÄ **Key Features**

### **1. Real-Time Gesture Recognition**  
- Utilizes **MediaPipe** for precise extraction of keypoints from **hands, face, and body**, enabling dynamic tracking of gestures.  
- Seamlessly processes high-speed video streams to ensure immediate feedback.

### **2. Sequential Pattern Analysis**  
- Employs **LSTM neural networks** to capture and analyze the temporal relationships within gestures.  
- Effectively distinguishes between static and dynamic components of sign language for accurate recognition.

### **3. Advanced Validation Metrics**  
- Incorporates robust evaluation metrics including:  
  - **F1-Score**: Measures balance between precision and recall.  
  - **Confusion Matrix**: Offers insight into class-specific prediction accuracy.  
  - **ROC Curves**: Visualizes true positive rates vs. false positive rates for each class.  

### **4. Optimized Data Pipeline**  
- Prepares training data by extracting and storing keypoints in **efficient formats** (e.g., `.h5` files) for faster processing.  
- Supports large-scale datasets with minimal resource overhead.  

### **5. Intelligent Preprocessing**  
- Filters and aligns gesture sequences for enhanced model performance.  
- Implements feature normalization to reduce variability caused by environmental or individual factors.

---

## üéØ **Project Milestones**

### **Current Achievements**  
- **üìå High Precision Rates**: Achieved competitive accuracy in recognizing over 10 Peruvian sign gestures.  
- **‚úÖ Optimized Model Architecture**: Enhanced gesture recognition through hyperparameter tuning and data augmentation techniques.  
- **üåê Societal Impact**: The project highlights the potential for real-world application in schools, workplaces, and public institutions, fostering accessibility.  

### **Ongoing Work**  
- Expanding the **gesture vocabulary** to accommodate complex sign language phrases.  
- Preparing for publication in **high-impact scientific journals**, emphasizing its role in inclusive technology development.

---

## üíª **Technologies and Tools**

### **Frameworks and Libraries**  
- **MediaPipe**: For extracting skeletal features from video streams.  
- **OpenCV**: For video preprocessing and handling.  

### **Deep Learning Models**  
- **LSTM Networks**: For analyzing temporal relationships in gesture sequences.  

### **Development Environment**  
- **Python**: Core programming language for system implementation.  
- **Google Colab & Visual Studio Code**: Platforms for experimentation and development.  

---

## üåü **Vision and Goals**  
The primary goal of this project is to:  
1. Create an innovative **sign language recognition system** that operates in real-time.  
2. Support **educational equity** by providing a tool for learning and teaching Peruvian Sign Language.  
3. Enable **inclusive communication** between the deaf community and society, enhancing opportunities for interaction and collaboration.

---

## üì∑ **Visual Highlights**

### **1. Workflow Diagram**  
- Displays the step-by-step process from gesture capture to model prediction.

### **2. Gesture Keypoint Samples**  
- Screenshots of extracted keypoints (hands, face, and body) using MediaPipe.
![Arquitectura del Proyecto](https://github.com/user-attachments/assets/31ed259b-9d75-42a2-913e-d50942083f9a)
![Adquisicion de datos](https://github.com/user-attachments/assets/1a30c1bc-4b4b-4980-9197-a041360e0b09)
![Preprocesamiento de imagen](https://github.com/user-attachments/assets/36134a78-3f9e-42ab-b659-cf2b107fcbf4)

### **3. Performance Metrics**  
- Graphs depicting **ROC curves, confusion matrices**, and accuracy over time to demonstrate the model's effectiveness.
![Curva ROC](https://github.com/user-attachments/assets/a2b06887-a8e2-4cf6-937c-5f1a935d03b5)
![Matriz de Confusion](https://github.com/user-attachments/assets/54725c73-94ec-430c-91a1-db359f638348)
![Especificidad](https://github.com/user-attachments/assets/47e2bcbf-d973-4820-890c-007bb7443621)

### **4. Real-Time Demonstration**  
- Video showcasing the system‚Äôs ability to detect and interpret Peruvian sign language gestures in a live environment.
![Evaluacion en Tiempo Real](https://github.com/user-attachments/assets/bcfa0b47-9221-47c7-b719-a5770859df6f)

---

## üë• **Contributors**

- **[Jharold Mayorga Villena](https://github.com/MayogaDev)**  
- **[Andrea Lopez Condori](https://github.com/andrealopezco20)**  
- **[Javier Quispe Rojas](https://github.com/XawiiQR)**  
- **[Jenny Huanca Anquise](https://github.com/JennyHa-Unsa)**  

---

## üë• **Acknowledgments**  
This project is proudly conducted in collaboration with the **Universidad Nacional de San Agust√≠n de Arequipa**, with contributions from researchers and students dedicated to advancing accessibility technologies.  
